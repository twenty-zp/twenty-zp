<!DOCTYPE html><html lang="zh-Hans"><head><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><title> 三、视频编解码-解码篇 · Twenty's 时间念</title><meta name="description" content="三、视频编解码-解码篇 - Twenty's 时间念"><meta name="viewport" content="width=device-width, initial-scale=1"><link rel="short icon" href="/favicon1.png"><link rel="stylesheet" href="/css/apollo.css"><script src="/baiduAnalyse.js"></script><link rel="search" type="application/opensearchdescription+xml" href="http://blog.img421.com/atom.xml" title="Twenty's 时间念"></head><body><div class="wrap"><header><a href="/" class="logo-link"><img src="/favicon.png"></a><ul class="nav nav-list"><li class="nav-list-item"><a href="/" target="_self" class="nav-list-link">BLOG</a></li><li class="nav-list-item"><a href="/archives/" target="_self" class="nav-list-link">ARCHIVE</a></li><li class="nav-list-item"><a href="https://github.com/twenty-zp" target="_blank" class="nav-list-link">GITHUB</a></li><li class="nav-list-item"><a href="/atom.xml" target="_self" class="nav-list-link">RSS</a></li></ul></header><section class="container"><div class="post"><article class="post-block"><h1 class="post-title">三、视频编解码-解码篇</h1><div class="post-info">Aug 5, 2016</div><div class="post-content"><p><a href="https://github.com/twenty-zp/RealTimeAVVideo" target="_blank" rel="external">Demo地址</a></p>
<p>在此之前我们通常使用的FFmpeg多媒体库,利用CPU来进行视频的编解码,占用CPU资源,效率低下,俗称软编解码.而苹果在2014年的iOS8中,开放了VideoToolbox.framwork框架,此框架使用GPU或专用的处理器来进行编解码,俗称硬编解码.而此框架在此之前只有MAC OS系统中可以使用,在iOS作为私有框架.终于苹果在iOS8.0中得到开放引入.</p>
<p>2014年的WWDC<a href="https://developer.apple.com/videos/play/wwdc2014/513/" target="_blank" rel="external">Direct Access to Video Encoding and Decoding</a>中,苹果介绍了使用videoToolbox硬编解码.<br>使用硬编解码有几个优点:</p>
<ul>
<li>提高性能;</li>
<li>增加效率;</li>
<li>延长电量的使用</li>
</ul>
<p>对于编解码,AVFoundation框架只有以下几个功能:</p>
<ol>
<li>直接解压后显示;</li>
<li>直接压缩到一个文件当中;</li>
</ol>
<p>而对于Video Toolbox,我们可以通过以下功能获取到数据,进行网络流传输等多种保存：</p>
<ol>
<li>解压为图像的数据结构;</li>
<li><p>压缩为视频图像的容器数据结构.</p>
<h3 id="一、videoToolbox的基本数据"><a href="#一、videoToolbox的基本数据" class="headerlink" title="一、videoToolbox的基本数据"></a>一、videoToolbox的基本数据</h3><p>Video Toolbox视频编解码前后需要应用的数据结构进行说明。</p>
</li>
<li><p>CVPixelBuffer：编码前和解码后的图像数据结构。此内容包含一系列的CVPixelBufferPool内容</p>
</li>
<li><p>CMTime、CMClock和CMTimebase：时间戳相关。时间以64-bit/32-bit的形式出现。</p>
</li>
<li><p>pixelBufferAttributes:字典设置.可能包括Width/height、pixel format type、• Compatibility (e.g., OpenGL ES, Core Animation)</p>
</li>
<li><p>CMBlockBuffer：编码后，结果图像的数据结构。</p>
</li>
<li><p>CMVideoFormatDescription：图像存储方式，编解码器等格式描述。</p>
</li>
<li><p>(CMSampleBuffer：存放编解码前后的视频图像的容器数据结构。</p>
</li>
<li><p>CMClock </p>
</li>
<li><p>CMTimebase: 关于CMClock的一个控制视图,包含CMClock、时间映射(Time mapping)、速率控制(Rate control)</p>
</li>
</ol>
<hr>
<p>由<a href="er_3001_cai_ji_shi_pin.md">二、采集视频数据</a>可知,我们获取到的数据<code>(CMSampleBufferRef)sampleBuffer</code>为未编码的数据;<br><img src="https://twenty-zp.gitbooks.io/-/content/AFBF71FB-4A38-449B-97FC-EBE4BAC1A3F6.png" alt="图1.1编码前后的数据结构示意图"><br><strong>图1.1</strong><br>上图中,编码前后的视频图像都封装在<code>CMSampleBuffer</code>中,编码前以<code>CVPixelBuffer</code>进行存储;编码后以<code>CMBlockBuffer</code>进行存储。除此之外两者都包括<code>CMTime</code>、<code>CMVideoFormatDesc</code>.</p>
<h3 id="二、获取已编码数据流进行解码展示-获取编码后的数据进行解码展示"><a href="#二、获取已编码数据流进行解码展示-获取编码后的数据进行解码展示" class="headerlink" title="二、获取已编码数据流进行解码展示(获取编码后的数据进行解码展示)"></a>二、获取已编码数据流进行解码展示(获取编码后的数据进行解码展示)</h3><p><img src="https://twenty-zp.gitbooks.io/-/content/6738D208-3D91-4C81-8C09-E9F212FAC080.png" alt="图2.1"><br><strong>图2.1</strong><br>通过网络获取<strong>已编码的H.264数据流</strong>进行<strong>MPEG-4</strong>处理,通过使用<code>AVSampleBufferDisplayLayer</code>解码获取图像显示到设备上。<br><img src="https://twenty-zp.gitbooks.io/-/content/C9B77B4F-5091-4C80-92DE-D84C9AB44D25.png" alt="图2.2 AVSampleBufferDisplayLayer解码显示"><br><strong>图2.2</strong></p>
<p>2.1. 将获取到的<strong>已编码的数据流</strong>进行处理成<code>CMSampleBuffer</code>.<br><img src="https://twenty-zp.gitbooks.io/-/content/DEA65059-66BE-49E3-BF53-5938CB278F36.png" alt="图2.3 处理H.264码流"><br><strong>图2.3</strong><br>由图1.1可知:解码前的图像数据结构$$CMSampleBuffer = CMTime + FormatDesc + CMBlockBuffer$$组成 因此需要从H.264的码流需要以上三个信息组合成<code>CMSampleBuffer</code>.</p>
<blockquote>
<p>H.264码流由一系列的NALU单元组成.NALU单元包含视频图像数据(或视频帧片段)和H.264的参数信息。其中视频图像信息数据是CMBlockBuffer,而H.264参数信息可以组合成FormatDesc,包括编码所用的profile，level，图像的宽和高，deblock滤波器等.具体包含<strong>第一个NALU的SPS</strong>（Sequence Parameter Set）和<strong>第二个NALU的PPS</strong>（Picture Parameter Set）。</p>
</blockquote>
<p><img src="https://twenty-zp.gitbooks.io/-/content/F2D6F4FA-87C1-4B41-9295-6F4E1F8E43C7.png" alt="图2.3 H.264组成结构"><br><strong>图2.4</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">* frame的数据可以分为多个slice(片段). </div><div class="line">    * 每个slice中的数据，在帧内预测只用到自己slice的数据， 与其他slice 数据没有依赖关系。 </div><div class="line">    * NAL 是用来将编码的数据进行大包的。 比如，每一个slice 数据可以放在NAL 包中。</div><div class="line">    * I frame 是自己独立编码，不依赖于其他frame 数据。 </div><div class="line">    * P frame 依赖 I frame 数据。 </div><div class="line">    * B frame 依赖 I frame, P frame 或其他 B frame 数据。</div><div class="line">    * H.264码流的第三个NALU是IDR(即时解码器刷新),IDR图像都是I帧，H.264引入IDR图像为了解码的同步,使错</div><div class="line">     误不被传播，当解码器解码到IDR图像时，立即将参考帧队列清空，将已解码的数据全部输出或抛弃，重新查找参数集，</div><div class="line">     开一个新的序 列。这样，如果前一个序列出现重大错误，在这里可以获得重新同步的机会。IDR图像之后的图像永远不</div><div class="line">     会使用IDR之前的图像的数据来解码。</div></pre></td></tr></table></figure></p>
<p> <strong>1.1 使用<code>CMVideoFormatDescriptionCreateFromH264ParameterSets</code>提取编码的SPS和PPS压缩转换成<code>MPEG—4</code>需要的SPS和PPS,组合成<code>CMVideoFormatDescription</code></strong><br><img src="https://twenty-zp.gitbooks.io/-/content/9F927C1A-288F-44DF-BB7B-9B5804C55562.png" alt="图2.1.1"><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">(1)每个NALU的开始码是3或4字节头:00 00 01 或 00 00 00 01,按开始码可定位NALU;</div><div class="line">(2)提取出SPS和PPS,通过获取到的编码流,判断开始码后的第一个byte的后5位,7代表SPS,8代表PPS;</div><div class="line">(3)CMVideoFormatDescriptionCreateFromH264ParameterSets函数构建CMVideoFormatDescription.</div></pre></td></tr></table></figure></p>
<p>   <strong>1.2 获取CMBlockBuffer</strong><br>  <img src="https://twenty-zp.gitbooks.io/-/content/FCACB659-4B39-4497-BDF4-246499F94EAC.png" alt="图2.1.2"><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">(1)通过开始码,定位到NALU;</div><div class="line">(2)确认类型数据将开始码替换为NALU的长度信息（4 Byte）</div><div class="line">(3)通过CMBlockBufferCreateWithMemoryBlock接口构造CMBlockBufferRef</div></pre></td></tr></table></figure></p>
<p>   <strong>1.3 添加CMTime</strong><br>  <img src="https://twenty-zp.gitbooks.io/-/content/BAC15B30-4D58-4ECD-A3EF-C924F61759F4.png" alt="图2.5"></p>
</div></article></div></section><footer><div class="paginator"><a href="/2016/08/05/si-shi-pin-de-bian-jie-ma-bian-ma-pian/" class="prev">PREV</a><a href="/2016/08/05/shi-pin-zhi-bo-xi-lie-er-cai-ji-shi-pin-shu-ju/" class="next">NEXT</a></div><div class="copyright"><p>© 2015 - 2017 <a href="http://blog.img421.com">Twenty's 时间念</a>.</p></div></footer></div><script async src="//cdn.bootcss.com/mathjax/2.6.1/MathJax.js?config=TeX-MML-AM_CHTML"></script></body></html>